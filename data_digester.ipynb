{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "import data_module as dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "\n",
    "dataset_path = '~/datasets'\n",
    "cuda = 0\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "max_epochs = 2\n",
    "\n",
    "\n",
    "x_dim  = 3072\n",
    "hidden_dim = 432\n",
    "latent_dim = 64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# default version --effectively no transforms\n",
    "cifar_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=9, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=9, out_channels=27, kernel_size=4, stride=2, padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "#takes input from [batch, latent]\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 32, 32)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, hidden_dim)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class DeConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.deconv0 = nn.Linear(in_features=432, out_features=1728) # corresponds to encoder max pool layer\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=27, out_channels=9, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=9, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.deconv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 27, 8, 8)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 3072)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Custom loss tracking feature. Populates array with loss according to source. Throws error when max epochs exceeded\n",
    "batch_index = 0\n",
    "max_iterations = len(dm.module.train_dataloader())+3\n",
    "loss_array = np.zeros(shape=(3,ceil(max_iterations*max_epochs)))\n",
    "def render(self, *args):\n",
    "    indexer = 0\n",
    "    global batch_index\n",
    "    for loss_category in args:\n",
    "            try:\n",
    "                loss_array[indexer][batch_index] = loss_category\n",
    "                np.save('loss_array_2', loss_array)\n",
    "            except IndexError:\n",
    "                print('done with specified number of iterations')\n",
    "                np.save('loss_array_2', loss_array)\n",
    "                sys.exit()\n",
    "            indexer += 1\n",
    "    batch_index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 1414)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_array.shape\n",
    "#[3, max_epochs*batches_per]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#The encoder models the approximate posterior distribution of the latent variables Z given the observed data X. It's denoted as q(Z|X), which is an approximation to the true posterior distribution p(Z|X).\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv = ConvNet()\n",
    "        self.FC_mean  = nn.Sequential(nn.Linear(hidden_dim, latent_dim*2), nn.Linear(latent_dim*2, latent_dim))\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        self.ReLU = nn.ReLU(0.2)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x      = self.ReLU(self.conv(x))\n",
    "        mean     = self.FC_mean(x)\n",
    "        logvar  = self.FC_var(x)\n",
    "\n",
    "\n",
    "        return mean, logvar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# The decoder models the likelihood of the observed data X given the latent variables Z. It's denoted as p(X|Z).\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.reconstructor = DeConvNet()\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h     = self.ReLU(self.FC_hidden(x))\n",
    "        x_hat     = self.ReLU(self.reconstructor(h))\n",
    "        return x_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# high level model declaration. See above for layer structure\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)\n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * logvar)) # convert logvar to sigma\n",
    "        x_hat            = self.Decoder(z)\n",
    "\n",
    "        return x_hat, mean, logvar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# takes input from 3072, gives output of 192\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, logvar):\n",
    "    # (Q(z|x)[log P(x|z)]\n",
    "    reconstruction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    # KL(Q(z|x) || P(z|x))\n",
    "    KL_Div      = - 0.5 * torch.sum(1+ logvar - mean.pow(2) - logvar.exp())\n",
    "    render(reconstruction_loss, KL_Div, (reconstruction_loss+KL_Div))\n",
    "    return reconstruction_loss + KL_Div\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_and_upload_image(tensor_batch, filename):\n",
    "    \"\"\"\n",
    "    Save and upload the 0th element of a batched tensor as an image.\n",
    "\n",
    "    Args:\n",
    "    tensor_batch (torch.Tensor): Batched tensor.\n",
    "    filename (str): The name of the file to save the image as.\n",
    "    \"\"\"\n",
    "    # Take the 0th element of the batch\n",
    "    img_tensor = tensor_batch[0].view(3, 32, 32)\n",
    "\n",
    "    # Convert the tensor to a NumPy array and normalize the pixel values to the range [0, 255]\n",
    "    img_array = (img_tensor.detach().permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
    "    #img_array = (img_tensor.detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    img = Image.fromarray(img_array)\n",
    "    img.save(filename)\n",
    "\n",
    "\n",
    "# Call the function with the batched tensor and desired filename\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss right now is:  tensor(45629.5312, grad_fn=<AddBackward0>)\n",
      "saving outmage\n",
      "loss right now is:  tensor(23049.1016, grad_fn=<AddBackward0>)\n",
      "loss right now is:  tensor(12782.9072, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Check hyperparams and paths before running this training loop!\n",
    "data = dm.module\n",
    "data.setup('train')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(max_epochs):\n",
    "    loss = 0\n",
    "    for i, (x, _) in enumerate(data.train_dataloader()):\n",
    "        x = x.view(-1, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, logvar = model(x)\n",
    "#log loss every 25 steps, save images every 1500 steps\n",
    "        loss = loss_function(x, x_hat, mean, logvar)\n",
    "        if i % 25 == 0:\n",
    "            print('loss right now is: ', loss)\n",
    "            if i % 1500 == 0:\n",
    "                print('saving outmage')\n",
    "                save_and_upload_image(x, \"inmage.png\")\n",
    "                save_and_upload_image(x_hat, \"outmage.png\")\n",
    "\n",
    "        loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(\"Epoch\", epoch + 1, \"complete!\", \"Average Loss: \", loss / (i*batch_size))\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
